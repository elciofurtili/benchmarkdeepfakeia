
# Projeto de Benchmark de Modelos de IA na DetecÃ§Ã£o de Deepfakes em Ãudio

Este projeto implementa e compara trÃªs modelos de inteligÃªncia artificial â€” **CNN**, **RNN-LSTM** e **Wav2Vec 2.0** â€” aplicados na tarefa de detecÃ§Ã£o de fraudes em Ã¡udios gerados por tecnologias de *deepfake*. O objetivo Ã© avaliar a eficÃ¡cia de cada arquitetura na identificaÃ§Ã£o de Ã¡udios manipulados, considerando diferentes abordagens de modelagem.

Os script foram executados utilizando [ROCm](https://github.com/ROCm/ROCm)

Apesar de parecer que estÃ¡ buscando "CUDA", o PyTorch com ROCm mapeia internamente isso para a GPU AMD corretamente, desde que:
- O PyTorch tenha sido instalado com suporte a ROCm e vocÃª esteja com `HIP_VISIBLE_DEVICES` e drivers ROCm corretamente configurados.

```bash
pip install torch --index-url https://download.pytorch.org/whl/rocm5.7
``` 

## ğŸš€ Estrutura do Projeto

```
/deepfake-audio-benchmark
â”œâ”€â”€ models/                       # ImplementaÃ§Ã£o dos modelos
â”‚   â”œâ”€â”€ cnn_model.py
â”‚   â”œâ”€â”€ rnn_lstm_model.py
â”‚   â””â”€â”€ wav2vec_model.py
â”œâ”€â”€ data/                         # Dados de Ã¡udio organizados
â”‚   â””â”€â”€ audios/
â”‚       â”œâ”€â”€ real/
â”‚       â””â”€â”€ fake/
â”œâ”€â”€ reports/                      # RelatÃ³rios e mÃ©tricas geradas
â”‚   â””â”€â”€ metrics_report.csv
â”œâ”€â”€ utils.py                      # FunÃ§Ãµes auxiliares
â”œâ”€â”€ database.py                    # Gerenciamento de dados locais
â”œâ”€â”€ main.py                        # Interface CLI para execuÃ§Ã£o
â”œâ”€â”€ requirements.txt               # DependÃªncias
â””â”€â”€ README.md                      # Este documento
```

## ğŸ”¥ Modelos Implementados

- **CNN**: Convolutional Neural Network aplicada sobre espectrogramas.
- **RNN-LSTM**: Rede recorrente com Long Short-Term Memory para sequÃªncias acÃºsticas.
- **Wav2Vec 2.0**: Modelo prÃ©-treinado baseado em Transformers para representaÃ§Ã£o de Ã¡udio bruto.

## ğŸ“Š MÃ©tricas Avaliadas

- **AcurÃ¡cia**
- **PrecisÃ£o**
- **Recall**
- **F1-Score**
- **AUC-ROC**

Os relatÃ³rios sÃ£o gerados automaticamente na pasta `/reports/metrics_report.csv`.

## ğŸ“¦ DependÃªncias

- `torch` (PyTorch)
- `torchaudio`
- `librosa`
- `scikit-learn`
- `pandas`
- `tqdm`
- `transformers`
- `matplotlib`

InstalaÃ§Ã£o recomendada:

```bash
pip install -r requirements.txt
```

## âš™ï¸ Como Executar

1. Organize seus Ã¡udios na pasta `/data/audios/real` e `/data/audios/fake`.
2. Execute via linha de comando:

```bash
python main.py --model cnn
python main.py --model rnn
python main.py --model wav2vec
```

3. Os resultados serÃ£o salvos na pasta `/reports`.

## ğŸ“š Datasets Utilizados

|  Dataset  | Tipo de Ataques  | Ãudios (Real/Fake) | LÃ­ngua        | ReferÃªncia |
|------------|------------------|---------------------|----------------|------------|
| CVoiceFake | Vocoder          | 23.544 / 91.700     | MultilÃ­ngue    | [Link](https://dl.acm.org/doi/10.1145/3658644.3670285) |
| MLADDC     | Vocoder          | 80.000 / 160.000    | MultilÃ­ngue    | [Link](https://openreview.net/forum?id=ic3HvoOTeU) |
| VSASV      | VC, Replay, Adv. | 164.000 / 174.000   | MultilÃ­ngue    | [Link](https://www.isca-archive.org/interspeech_2024/hoang24b_interspeech.html) |

## ğŸ“ Artigo Relacionado

Este projeto Ã© base para o artigo produzido na disciplina de InteligÃªncia Artificial (2025), disponÃ­vel em: [Artigo PDF](https://github.com/elciofurtili/deepfake-audio-benchmark/blob/main/artigo.pdf)